{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_wordvecs(path):\n",
    "    wordframe = pd.read_table(path, sep=\" \", header=None, quoting=csv.QUOTE_NONE)\n",
    "    words = wordframe[0]\n",
    "    wordvecs = wordframe.drop(columns=0).values.T\n",
    "\n",
    "    word_index = {}\n",
    "    for idx, w in enumerate(wordframe[0]):\n",
    "        word_index[w] = idx\n",
    "        \n",
    "    word_norms = np.zeros((wordvecs.shape[1],))\n",
    "    for i in range(wordvecs.shape[1]):\n",
    "        word_norms[i] = np.linalg.norm(wordvecs[:,i])\n",
    "        \n",
    "    return words, wordvecs, word_index, word_norms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "words, wordvecs, word_index, word_norms = load_wordvecs(\"glove.840B.300d.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab size is 2196017\n"
     ]
    }
   ],
   "source": [
    "print(\"vocab size is\", wordvecs.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Toplist:\n",
    "    def __init__(self, size, keyfn):\n",
    "        self.min = None\n",
    "        self.max = None\n",
    "        self.size = size\n",
    "        self.keyfn = keyfn or (lambda x: x)\n",
    "        self.items = []\n",
    "        \n",
    "    def _calc_min_max(self):\n",
    "        min_ = None\n",
    "        max_ = None\n",
    "        for i in self.items:\n",
    "            if min_ is None or self.keyfn(min_) > self.keyfn(i):\n",
    "                min_ = i\n",
    "            if max_ is None or self.keyfn(max_) < self.keyfn(i):\n",
    "                max_ = i\n",
    "        self.min = min_\n",
    "        self.max = max_\n",
    "        \n",
    "    def push(self, item):\n",
    "        if len(self.items) < self.size:\n",
    "            self.items.append(item)\n",
    "            self._calc_min_max()\n",
    "        else:\n",
    "            key = self.keyfn(item)\n",
    "            if key <= self.keyfn(self.min):\n",
    "                return\n",
    "            self.items.remove(self.min)\n",
    "            self.items.append(item)\n",
    "            self._calc_min_max()\n",
    "\n",
    "def find_word(word):\n",
    "    wi = word_index[word]\n",
    "    wv = wordvecs[:,wi]\n",
    "    wn = word_norms[wi]\n",
    "    return (wi, wv, wn)\n",
    "\n",
    "def make_target(wv):\n",
    "    return (None, wv, np.linalg.norm(wv))\n",
    "\n",
    "def cos_sim(a, b):\n",
    "    return np.dot(a[1], b[1]) / (a[2] * b[2])\n",
    "\n",
    "def find_closest(target, n):\n",
    "    topwords = Toplist(n + 1, lambda x: x[1])\n",
    "    for i in range(wordvecs.shape[1]):\n",
    "        cand = (i, wordvecs[:,i], word_norms[i])\n",
    "        sim = cos_sim(target, cand)\n",
    "        topwords.push((i, sim))\n",
    "    return [(words[i], s) for (i, s) in sorted(topwords.items, key=lambda x: -x[1])[1:]]        \n",
    "\n",
    "def find_synonyms(word, n):\n",
    "    target = find_word(word)\n",
    "    return find_closest(target, n)\n",
    "\n",
    "def solve_analogy(a, b, c, n):\n",
    "    at = find_word(a)\n",
    "    bt = find_word(b)\n",
    "    ct = find_word(c)\n",
    "    guess = bt[1] - at[1] + ct[1]\n",
    "    return find_closest(make_target(guess), n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('straightforward', 0.7598401789000424),\n",
       " ('easy', 0.7527235589305407),\n",
       " ('simplest', 0.698272448362614),\n",
       " ('basic', 0.684735295654891),\n",
       " ('simpler', 0.6550425162533078),\n",
       " ('quick', 0.6546937970492189),\n",
       " ('simply', 0.6456051957769307),\n",
       " ('Simple', 0.6379334979408947),\n",
       " ('make', 0.6294584219950387),\n",
       " ('neat', 0.62700226328513),\n",
       " ('way', 0.625465131086621),\n",
       " ('kind', 0.6221105383923256),\n",
       " ('complicated', 0.6185878422461943),\n",
       " ('easier', 0.6119539330710158),\n",
       " ('simplistic', 0.6081463102432625)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_synonyms('simple', 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('fantastic', 0.8591595791816141),\n",
       " ('lovely', 0.8388477050475734),\n",
       " ('fabulous', 0.8359376678974116),\n",
       " ('amazing', 0.8156014577622631),\n",
       " ('great', 0.8059450072940098),\n",
       " ('marvelous', 0.8023499439044458),\n",
       " ('beautiful', 0.7896219657457448),\n",
       " ('delightful', 0.7839891580590513),\n",
       " ('terrific', 0.775186249661481),\n",
       " ('gorgeous', 0.7233308378389621),\n",
       " ('wonderfully', 0.7219120388363572),\n",
       " ('awesome', 0.7182067151596504),\n",
       " ('incredible', 0.7168842503985587),\n",
       " ('nice', 0.7063791247499048),\n",
       " ('inspiring', 0.7040061156673134)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_synonyms('wonderful', 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('queen', 0.7880844291841294),\n",
       " ('prince', 0.6401077949675448),\n",
       " ('kings', 0.6208543934897167),\n",
       " ('princess', 0.6125636524073936),\n",
       " ('royal', 0.5800970791610943)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solve_analogy('man', 'king', 'woman', 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('leaf', 0.7391099662079962),\n",
       " ('flowers', 0.6810389249054707),\n",
       " ('petals', 0.677353549710753),\n",
       " ('petal', 0.6751669154136666),\n",
       " ('floral', 0.6213623994091388)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solve_analogy('tree', 'leaf', 'flower', 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('cat', 0.8533778446069686),\n",
       " ('puppy', 0.8248203189011132),\n",
       " ('kittens', 0.7661139728453404),\n",
       " ('pup', 0.7530981677990902),\n",
       " ('kitty', 0.7515497639056455)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solve_analogy('dog', 'puppy', 'cat', 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('out', 0.6714371583257094),\n",
       " ('down', 0.6469337262680082),\n",
       " ('get', 0.6134338430239189),\n",
       " ('going', 0.5983556643455921),\n",
       " ('put', 0.5968824404289338)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solve_analogy('white', 'black', 'up', 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('bear', 0.5394098004124965),\n",
       " ('itself', 0.4416594674163141),\n",
       " ('lion', 0.4076591831253801),\n",
       " ('wolf', 0.40610565815910354),\n",
       " ('grizzly', 0.3957266725509989),\n",
       " ('teddy', 0.3858165815967754),\n",
       " ('beast', 0.37727804992840114),\n",
       " ('lair', 0.37326781836920003),\n",
       " ('lions', 0.3720534335594756),\n",
       " ('cubs', 0.371431507794096)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solve_analogy('bees', 'hive', 'bears', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
