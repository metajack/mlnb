{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordframe = pd.read_table(\"glove.42B.300d.txt\", sep=\" \", header=None, quoting=csv.QUOTE_NONE)\n",
    "wordvecs = wordframe.drop(columns=0).values.T\n",
    "\n",
    "word_index = {}\n",
    "for idx, w in enumerate(wordframe[0]):\n",
    "    word_index[w] = idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2vec(word):\n",
    "    idx = word_index[word]\n",
    "    return wordvecs[:,idx]\n",
    "\n",
    "def cos_sim(a, b):\n",
    "    return (np.dot(a, b) / (np.sqrt(np.dot(a, a)) * np.sqrt(np.dot(b, b))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0000000000000002\n",
      "0.7759782144883963\n"
     ]
    }
   ],
   "source": [
    "print(cos_sim(word2vec('the'), word2vec('the')))\n",
    "print(cos_sim(word2vec('a'), word2vec('the')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_closest(wv, n):\n",
    "    sims = [(idx, cos_sim(wv, wordvecs[:,idx])) for idx in range(wordvecs.shape[1])]\n",
    "    scores = sorted(sims, key=operator.itemgetter(1, 0), reverse=True)\n",
    "    top = scores[1:n+1]\n",
    "    top_words = [(wordframe[0][i], score) for i, score in top]\n",
    "    return top_words\n",
    "\n",
    "def find_synonyms(word, n):\n",
    "    wv = word2vec(word)\n",
    "    return find_closest(wv, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('depressing', 0.6871760913711346),\n",
       " ('sorry', 0.6800469815345019),\n",
       " ('sadly', 0.6717799399716502),\n",
       " ('pathetic', 0.6704121421696385),\n",
       " ('tragic', 0.6591917754988509),\n",
       " ('funny', 0.6548493765323571),\n",
       " ('kinda', 0.6547635219788633),\n",
       " ('unhappy', 0.6436547720082669),\n",
       " ('happy', 0.64359088270462),\n",
       " ('awful', 0.6426853220313836)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_synonyms('sad', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_analogy(a, b, c, n):\n",
    "    av = word2vec(a)\n",
    "    bv = word2vec(b)\n",
    "    cv = word2vec(c)\n",
    "    guess = bv - av + cv\n",
    "    return find_closest(guess, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('queen', 0.7852211802171629),\n",
       " ('prince', 0.6025958343386526),\n",
       " ('princess', 0.5830840998108826),\n",
       " ('elizabeth', 0.5545557845397115),\n",
       " ('woman', 0.5479353384064566)]"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solve_analogy('man', 'king', 'woman', 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('leaf', 0.7213918136564571),\n",
       " ('flowers', 0.6268049978086533),\n",
       " ('petal', 0.6077496442464622),\n",
       " ('floral', 0.5882048928142201),\n",
       " ('petals', 0.5837074814311084)]"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solve_analogy('tree', 'leaf', 'flower', 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('kitten', 0.7830060073888362),\n",
       " ('puppy', 0.7784001658859766),\n",
       " ('kittens', 0.6804946836129994),\n",
       " ('cats', 0.6548770614342793),\n",
       " ('puppies', 0.6275406757725545)]"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solve_analogy('dog', 'puppy', 'cat', 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
